# ğŸ§  Question 10 â€“ Improving ANFIS Approximation Performance

> **Ø¥Ø¬Ø§Ø¨Ø© Ø³Ø¤Ø§Ù„ 10 ÙƒØ§Ù…Ù„Ø© ÙˆÙ…ÙÙ†Ø¸Ù…Ø©**  
> ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ANFIS - Ø´Ø±Ø­ Ø´Ø§Ù…Ù„ + ØªÙÙƒÙŠÙƒ + Ù…Ù„Ø®Øµ Ø§Ù…ØªØ­Ø§Ù† ğŸ“š

---

## ğŸ“‹ Problem Statement | Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø¤Ø§Ù„

In **Question (9)**, an ANFIS model was designed to approximate the nonlinear function:

$$f(x) = -2x - x^2$$

**Task:** State which of the following modifications improve the approximation results, then design the improved model:

### ğŸ”„ Proposed Modifications

| Modification | Effect |
|-------------|---------|
| âœ… Increase MFs to **5** | âœ“ Improves coverage |
| âœ… Change to **Gaussian MF** | âœ“ Smoother approximation |
| âœ… Use **Hybrid Learning** | âœ“ Faster convergence |

---

## ğŸ“Š Improved ANFIS Specifications

| Parameter | Original (Q9) | Improved (Q10) |
|-----------|---------------|----------------|
| Training Data Pairs | 60 | 60 |
| Membership Functions | 3 Triangular | **5 Gaussian** |
| Learning Algorithm | Backpropagation | **Hybrid Learning** |
| Training Epochs | 100 | 100 |
| Number of Rules | 3 | **5** |
| Total Parameters | 15 | **20** |

---

## ğŸ”§ Implementation Steps

### 1ï¸âƒ£ Step 1: Generate Training Data

```matlab
clc; clear; close all;

n = 60;                                % Number of training samples
x1 = -10 + 20.*rand(n,1);              % Input x in range [-10,10]
y  = -2.*x1 - x1.^2;                   % f(x) = -2x - x^2
data = [x1 y];                         % Training data set
```

#### ğŸ’¡ Explanation

- âœ… Same nonlinear function as Question 9
- âœ… Same training dataset for fair comparison
- âœ… **ANFIS structure** will be enhanced

---

### 2ï¸âƒ£ Step 2: Define Improved ANFIS Parameters

```matlab
numMFs    = 5;               % Increased number of MFs
mfType    = 'gaussmf';       % Gaussian membership functions
numEpochs = 100;             % Number of training epochs
```

#### ğŸ’¡ Explanation

- âœ… **5 MFs** â†’ More rules â†’ Better approximation capability
- âœ… **Gaussian MFs** â†’ Smoother transitions between fuzzy sets
- âœ… **100 epochs** â†’ Sufficient training time

#### ğŸ“ Why Gaussian MF?

Gaussian membership functions:
$$\mu(x) = e^{-\frac{(x-c)^2}{2\sigma^2}}$$

- Provide **smooth** and **differentiable** transitions
- Better for **gradient-based** optimization
- **2 parameters** per MF: center $(c)$ and width $(\sigma)$

---

### 3ï¸âƒ£ Step 3: Generate Initial FIS Structure

```matlab
fismat1 = genfis1(data, numMFs, mfType);
```

#### ğŸ’¡ Explanation

The `genfis1` function generates:
- âœ… **5 Gaussian membership functions**
- âœ… **5 fuzzy rules**
- âœ… Initial (untrained) parameters

---

### 4ï¸âƒ£ Step 4: Train ANFIS Using Hybrid Learning

```matlab
[fismat2, trn_mse, tst_mse] = anfis(data, fismat1, numEpochs, NaN, data, 1);
```

#### ğŸ’¡ Explanation

- âœ… `1` selects **Hybrid Learning (HL)** algorithm
- âœ… HL combines **Least Squares** + **Backpropagation**
- âœ… `fismat2` is the **trained ANFIS model**

#### âš¡ Hybrid Learning Advantage

| Algorithm | Optimizes | Speed | Accuracy |
|-----------|-----------|-------|----------|
| BP only | All parameters via gradient descent | Slow | Moderate |
| **Hybrid** | Consequent (LS) + Premise (BP) | **Fast** | **High** |

---

### 5ï¸âƒ£ Step 5: Evaluate Improved ANFIS

```matlab
anfis_output = evalfis(x1, fismat2);
[x1 y anfis_output]
```

#### ğŸ’¡ Explanation

- âœ… The trained ANFIS output is calculated
- âœ… Results are compared with exact function output
- âœ… Better approximation than Question 9

---

### 6ï¸âƒ£ Step 6: Error Analysis

```matlab
AMSE = mean(trn_mse);
```

#### ğŸ’¡ Explanation

- âœ… **AMSE** = Average Mean Square Error over 100 epochs
- âœ… **Lower AMSE** compared to Question (9) indicates improved approximation
- âœ… Faster error reduction due to Hybrid Learning

---

### 7ï¸âƒ£ Step 7: Plot Results

#### ğŸ“ˆ MSE vs Epochs

```matlab
figure;
plot(1:numEpochs, trn_mse, 'LineWidth', 2, 'Color', 'b');
xlabel('Epochs'); 
ylabel('MSE');
title('Training Error over Epochs (Hybrid Learning)');
grid on;
```

**Purpose:** Visualize faster convergence compared to BP

---

#### ğŸ“Š Desired Output vs ANFIS Output

```matlab
figure;
plot(1:n, y, 'x', 'MarkerSize', 8, 'LineWidth', 1.5);
hold on;
plot(1:n, anfis_output, 'o', 'MarkerSize', 6);
xlabel('Sample Number'); 
ylabel('Output');
legend('Desired Output', 'ANFIS Output', 'Location', 'best');
title('Comparison: Desired vs ANFIS Output (5 Gaussian MFs)');
grid on;
hold off;
```

**Purpose:** Show improved match between desired and predicted outputs

---

## ğŸ¯ ANFIS Parameters Calculation | Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª

### ğŸ”¸ Premise Parameters

- **5 Gaussian MFs**
- Each Gaussian MF has **2 control parameters** (center $c$ and width $\sigma$)

$$\text{Number of premise parameters} = 2 \times 5 = 10 \text{ parameters}$$

---

### ğŸ”¸ Consequent Parameters

- **Sugeno-type** consequent function:
  $$f = ax + b$$
- **Number of rules** = 5

$$\text{Number of consequent parameters} = (1 + 1) \times 5 = 10 \text{ parameters}$$

---

### ğŸ”¸ Total ANFIS Parameters

| Parameter Type | Question 9 | Question 10 |
|----------------|------------|-------------|
| Premise Parameters | 9 (3 MFs Ã— 3) | **10 (5 MFs Ã— 2)** |
| Consequent Parameters | 6 (3 rules Ã— 2) | **10 (5 rules Ã— 2)** |
| **Total Parameters** | **15** | **20** |

#### ğŸ“Œ Display Optimized Values

```matlab
getfis(fismat2)
showrule(fismat2)
```

---

## ğŸ“Š Comparison: Question 9 vs Question 10

| Aspect | Question 9 | Question 10 | Improvement |
|--------|------------|-------------|-------------|
| **MF Type** | Triangular | Gaussian | Smoother approximation |
| **Number of MFs** | 3 | 5 | Better input space coverage |
| **Learning** | Backpropagation | Hybrid | Faster convergence |
| **Rules** | 3 | 5 | More flexible model |
| **Parameters** | 15 | 20 | Higher capacity |
| **AMSE** | Higher | **Lower** | âœ… Better accuracy |
| **Convergence** | Slower | **Faster** | âœ… Efficient training |

---

## âœ… Final Conclusion | Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©

> **The improved ANFIS model successfully achieves better approximation of the nonlinear function**  
> $$f(x) = -2x - x^2$$  
> using **5 Gaussian membership functions** and **Hybrid Learning** algorithm with significantly improved performance.

### ğŸ“ Key Improvements | Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

1. âœ… **More MFs (5 instead of 3)** â†’ Better coverage of input space
2. âœ… **Gaussian MFs** â†’ Smoother and more differentiable transitions
3. âœ… **Hybrid Learning** â†’ Combines LS efficiency with BP flexibility
4. âœ… **Lower training error** â†’ More accurate approximation
5. âœ… **Faster convergence** â†’ Efficient optimization

### ğŸ”¬ Why These Modifications Work

- **Increased MFs**: More granular partitioning of input space allows finer approximation
- **Gaussian shape**: Smooth, bell-shaped curves provide better gradient information
- **Hybrid Learning**: LS optimizes linear parameters analytically (fast), BP optimizes nonlinear parameters via gradient descent

---

## ğŸ’¡ Exam Tips | Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø§Ù…ØªØ­Ø§Ù†

<details>
<summary><strong>Important Points to Remember</strong></summary>

1. **Gaussian MF** has **2 parameters** (center, width) vs Triangular has **3** (left, center, right)
2. **Hybrid Learning** (parameter = `1`) is **faster** than BP (parameter = `0`)
3. **More MFs** = More rules = Higher capacity but risk of overfitting
4. **Total parameters** = Premise + Consequent = $(p \times n_{MF}) + ((n_{inputs} + 1) \times n_{rules})$
5. Always compare **AMSE** to evaluate improvement

</details>

---

## ğŸ“š Additional Resources | Ù…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ©

<details>
<summary>ğŸ’¾ <strong>Save Options | Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø­ÙØ¸</strong></summary>

- ğŸ“„ Convert to **Word or PDF**
- âœï¸ Create **condensed exam version**
- ğŸ“Š Add **comparison charts**
- ğŸ“Œ Adjust according to **instructor's grading style**

</details>

---

**Good luck! ğŸŒŸ | Ø¨Ø§Ù„ØªÙˆÙÙŠÙ‚**
